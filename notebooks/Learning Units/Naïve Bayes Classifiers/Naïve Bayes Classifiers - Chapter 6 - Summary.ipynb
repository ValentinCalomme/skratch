{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "## Pros\n",
    "\n",
    "- Can be used for multi-class problems\n",
    "- Handles both discrete and continuous data\n",
    "- Model size is constant in the size of the data\n",
    "- Online learning is possible\n",
    "\n",
    "## Cons\n",
    "\n",
    "- Bad estimator of class probabilities\n",
    "- Naïve assumption rarely holds\n",
    "- Can be simplistic\n",
    "- Can be unstable with small amounts of data\n",
    "\n",
    "## Can any distribution be used?\n",
    "\n",
    "In theory yes. Any distribution can be plugged into the Naïve Bayes algorithm. On top of that, each feature could, in theory, follow a different custom distribution. However, it is quite rarely used in practice as Naïve Bayes is often used as a baseline, not a fine-tuned model.\n",
    "\n",
    "## Why is multinomial different than Bernoulli with binary features?\n",
    "\n",
    "A common misconception is that the Bernoulli distribution and the Multinomial distribution behave similarly if they face binary features. This is not true! The main difference lies in the fact that the Bernoulli distribution models the absence of features, whereas the Multinomial distribution is only affected by features that are present.\n",
    "\n",
    "> The answer to [this post](https://datascience.stackexchange.com/questions/27624/difference-between-bernoulli-and-multinomial-naive-bayes) explains this phenonemon quite nicely.\n",
    "\n",
    "## How to deal with large amounts of data?\n",
    "\n",
    "Because most probability distributions can be updated online, Naïve Bayes classifiers are well-suited for large amounts of data. This is also why they are often used as baselines for large problems. Indeed, they are able to provide a quick estimate of how “difficult” a problem is, which can lead to different design choices later on.\n",
    "\n",
    "## What happens when the Naïve assumption is violated?\n",
    "\n",
    "Violating the Naïve assumption occurs very often. However, it doesn’t always mean that it will have a negative impact. Indeed, the assumption becomes violated when features are dependent on each other. But, if the features that are dependent on each other happen to be good predictors, it might even help improve the classification. Intuitively, if the Naïve assumption is respected, all features are assumed to bring an equal amount of information to the model, however, when features are dependent on each other, this is not true anymore. This is like if, during a vote, certain people got to vote more than other people. If they voted for the good option, this will be fine, but if they voted for something incorrect, this will have a negative impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorials\n",
    "\n",
    "- [Machine Learning Mastery](https://machinelearningmastery.com/naive-bayes-tutorial-for-machine-learning/)\n",
    "- [DatumBox](http://blog.datumbox.com/machine-learning-tutorial-the-naive-bayes-text-classifier/)\n",
    "- [Analytics Vidhya](https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/)\n",
    "- [Python Machine Learning](https://pythonmachinelearning.pro/text-classification-tutorial-with-naive-bayes/)\n",
    "\n",
    "## Implementations\n",
    "\n",
    "- [sklearn](http://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "- [ML From scratch](https://github.com/eriklindernoren/ML-From-Scratch/blob/master/mlfromscratch/supervised_learning/naive_bayes.py)\n",
    "\n",
    "## Videos\n",
    "\n",
    "- [Victor Lavrenko](https://www.youtube.com/watch?v=os-NaA0ldGs&list=PLBv09BD7ez_6CxkuiFTbL3jsn2Qd1IU7B)\n",
    "- [Andrew Ng](https://www.youtube.com/watch?v=z5UQyCESW64)\n",
    "- [Udacity](https://www.youtube.com/watch?v=M59h7CFUwPU&t=80s)\n",
    "- [Luis Serrano](https://www.youtube.com/watch?v=kqSzLo9fenk)\n",
    "- [Edureka](https://www.youtube.com/watch?v=vz_xuxYS2PM)\n",
    "\n",
    "## Other\n",
    "\n",
    "- [Naive Bayes Classifier (wiki)](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n",
    "- [Bayes' Theorem (wiki)](https://en.wikipedia.org/wiki/Bayes%27_theorem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

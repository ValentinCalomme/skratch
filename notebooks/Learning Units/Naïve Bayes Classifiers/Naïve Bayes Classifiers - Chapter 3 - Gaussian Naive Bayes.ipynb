{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naïve Bayes\n",
    "\n",
    "One of the most common probability distribution to use with Naïve Bayes classification is the Gaussian distribution. Indeed, in many cases, features can be assumed to follow a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "from supervised.nb_classifier import NBClassifier\n",
    " \n",
    "EPSILON = 1E-16  # offset to avoid \"divide by zero\" errors\n",
    " \n",
    " \n",
    "class GaussianNB(NBClassifier):\n",
    " \n",
    "    def _pdf(self, x, mean, std):\n",
    " \n",
    "        num = np.exp(-((x - mean)**2) / (EPSILON + 2 * std**2))\n",
    "        den = np.sqrt(2 * np.pi * std**2) + EPSILON\n",
    " \n",
    "        return num / den"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting\n",
    "\n",
    "When features are expected to follow a normal distribution, fitting our model comes down to calculating the mean and standard deviation of each of our feature. This means that fitting the evidence comes down to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _fit_evidence(self, X):\n",
    "\n",
    "        feature_probas = []\n",
    "\n",
    "        for feature in X.T:  # iterate through the features instead of the samples\n",
    "\n",
    "            feature_probas.append(dict(mean=np.mean(feature),\n",
    "                                       n=len(feature),\n",
    "                                       std=np.std(feature, ddof=1)))\n",
    "\n",
    "        return np.array(feature_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also keep track of the number of features that were observed, which will be useful if we need to update the model. Fitting the likelihood then becomes trivial, as it is similar to fitting the evidence for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _fit_likelihood(self, X, y):\n",
    "\n",
    "        likelihood_ = []\n",
    "\n",
    "        for c in self.classes_:\n",
    "\n",
    "            samples = X[y == c]  # only keep samples of class c\n",
    "\n",
    "            likelihood_.append(self._fit_evidence(samples))\n",
    "\n",
    "        return np.array(likelihood_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting\n",
    "\n",
    "Assuming that our model is trained, we need to be able to make use of its state in order to compute the evidence and likelihood. We can then reuse the _pdf that was defined at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _get_evidence(self, sample):\n",
    "\n",
    "        evidence = 1.0\n",
    "\n",
    "        for i, feature in enumerate(sample):\n",
    "\n",
    "            mean = self.evidence_[i][\"mean\"]\n",
    "            std = self.evidence_[i][\"std\"]\n",
    "\n",
    "            evidence *= self._pdf(feature, mean, std)\n",
    "\n",
    "        return evidence\n",
    "\n",
    "    def _get_likelihood(self, sample, c):\n",
    "\n",
    "        likelihood = 1.0\n",
    "\n",
    "        for i, feature in enumerate(sample):\n",
    "\n",
    "            mean = self.likelihood_[i][\"mean\"]\n",
    "            std = self.likelihood_[i][\"std\"]\n",
    "\n",
    "            likelihood *= self._pdf(feature, mean, std)\n",
    "\n",
    "        return likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating\n",
    "\n",
    "Updating the model means that given new data, the standard deviation, and the mean for each feature has to be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _update_evidence(self, X):\n",
    "\n",
    "        for i, feature in enumerate(X.T):   # iterate through the features instead of the samples\n",
    "\n",
    "            self.evidence_[i] = self._update_mean_std_n(feature, self.evidence_[i])\n",
    "\n",
    "        return self.evidence_\n",
    "\n",
    "    def _update_likelihood(self, X, y):\n",
    "\n",
    "        for c in self.classes_:\n",
    "\n",
    "            samples = X[y == c]  # only keep samples of class c\n",
    "\n",
    "            for i, feature in enumerate(samples.T):  # iterate through the features instead of the samples\n",
    "\n",
    "                self.likelihood_[i] = self._update_mean_std_n(feature, self.likelihood_[i])\n",
    "\n",
    "        return self.likelihood_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exists a way to do this online for both the [mean](https://math.stackexchange.com/questions/106700/incremental-averageing) and the [standard deviation](https://math.stackexchange.com/questions/102978/incremental-computation-of-standard-deviation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _update_mean_std_n(self, feature, mean_std_n):\n",
    "\n",
    "        old_m = mean_std_n[\"mean\"]\n",
    "        old_std = mean_std_n[\"std\"]\n",
    "        old_n = mean_std_n[\"n\"]\n",
    "\n",
    "        n = old_n + len(feature)\n",
    "\n",
    "        m = (old_m * old_n + np.mean(feature) * n) / (old_n + n)\n",
    "\n",
    "        s = np.sqrt((old_n * (old_std**2 + (old_m - m)**2)\n",
    "                     + len(feature) * (np.var(feature)\n",
    "                                       + (np.mean(feature) - m)**2)\n",
    "                     ) / (old_n + len(feature)))\n",
    "\n",
    "        return dict(mean=m, std=std, n=n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naïve Bayes\n",
    "\n",
    "Another common distribution is the Bernoulli distribution. This one is often used with discrete, or even binary, data. This distribution has the advantage of modelling both the presence and the absence of a feature. If we used Bernoulli Naïve Bayes for a spam filter for instance, the fact that certain words are not in the e-mail will affect the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "from supervised.nb_classifier import NBClassifier\n",
    " \n",
    " \n",
    "class BernoulliNB(NBClassifier):\n",
    " \n",
    "    def _pdf(self, x, p):\n",
    " \n",
    "        return (1.0 - x) * (1.0 - p) + x * p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting\n",
    "\n",
    "A Bernoulli distribution is parameterized by a single parameter, which depends on the number of times each feature occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _fit_evidence(self, X):\n",
    "\n",
    "        feature_probas = []\n",
    "\n",
    "        for feature in X.T:  # take the transpose to iterate through the features instead of the samples\n",
    "\n",
    "            feature_probas.append(dict(count=len(feature<li><span class=\"pricing-mark\"></span></li>),\n",
    "                                       n=len(feature)))\n",
    "\n",
    "        return np.array(feature_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also keep track of the number of instances that were observed, which will be useful if we need to update the model. Fitting the likelihood then becomes trivial, as it is similar to fitting the evidence for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _fit_likelihood(self, X, y):\n",
    "\n",
    "        likelihood_ = []\n",
    "\n",
    "        for c in self.classes_:\n",
    "\n",
    "            samples = X[y == c]  # only keep samples of class c\n",
    "\n",
    "            likelihood_.append(self._fit_evidence(samples))\n",
    "\n",
    "        return likelihood_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting\n",
    "\n",
    "Assuming that our model is trained, we need to be able to make use of its state in order to compute the evidence and likelihood. We can then reuse the <i>_pdf</i> that was defined at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _get_evidence(self, sample):\n",
    "\n",
    "        evidence = 1.0\n",
    "\n",
    "        for i, feature in enumerate(sample):\n",
    "\n",
    "            count = self.evidence_[i][\"count\"]\n",
    "            n = self.evidence_[i][\"n\"]\n",
    "\n",
    "            evidence *= self._pdf(x=feature, p=count / n)\n",
    "\n",
    "        return evidence\n",
    "\n",
    "    def _get_likelihood(self, sample, c):\n",
    "\n",
    "        likelihood = 1.0\n",
    "\n",
    "        for i, feature in enumerate(sample):\n",
    "\n",
    "            count = self.likelihood_[i][\"count\"]\n",
    "            n = self.likelihood_[i][\"n\"]\n",
    "\n",
    "            likelihood *= self._pdf(x=feature, p=count / n)\n",
    "\n",
    "        return likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating\n",
    "\n",
    "Updating the model means that given new data, the counts of features has to be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _update_evidence(self, X):\n",
    "\n",
    "        for i, feature in enumerate(X.T):  # take the transpose to iterate through the features instead of the samples\n",
    "\n",
    "            self.evidence[i][\"count\"] += len(feature<li><span class=\"pricing-mark\"></span></li>)\n",
    "            self.evidence[i][\"n\"] += len(feature)\n",
    "\n",
    "        return self.evidence_\n",
    "\n",
    "    def _update_likelihood(self, X, y):\n",
    "\n",
    "        for i, c in enumerate(self.classes_):\n",
    "\n",
    "            samples = X[y == c]  # only keep samples of class c\n",
    "\n",
    "            for i, feature in enumerate(samples.T):  # take the transpose to iterate through the features instead of the samples\n",
    "\n",
    "                self.likelihood_[i][\"count\"] += len(feature<li><span class=\"pricing-mark\"></span></li>)\n",
    "                self.likelihood_[i][\"n\"] += len(feature)\n",
    "\n",
    "        return self.likelihood_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

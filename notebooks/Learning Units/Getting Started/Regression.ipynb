{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cd6a64cf2b8a4c0f",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression is a supervised task where a model maps input to a continuous output. More formally, a regression problem can be defined as learning a function $f$ that will map input variables $X = x_0, x_1,\\dots, x_{m-1}, x_{m}$ to a continuous target variable $y$ such that $f(x) = y$.\n",
    "\n",
    "So for instance, let's say that we have the following data:\n",
    "\n",
    "| Variable 1 | Variable 1 | Variable 3 | Variable 4 | Target variable |\n",
    "|------------|------------|------------|------------|:---------------:|\n",
    "| 1          | 2          | 3          | 4          | 10              |\n",
    "| 2          | 3          | 4          | 5          | 14              |\n",
    "| 3          | 4          | 5          | 6          | 18              |\n",
    "| ...        | ...        | ...        | ...        | ...             |\n",
    "| 2000       | 2001       | 2002       | 2003       | 8006            |\n",
    "\n",
    "We would want to learn some function such that $f(1,2,3,4) = 10$ and $f(2,3,4,5) = 14$ and so on.\n",
    "\n",
    "Regression is often compared to curve fitting, since it is trying to fit some function $f$ that will follow a similar curve as the data. For instance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](../../../source/visualization/images/regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating regression\n",
    "\n",
    "Machine learning is all about getting better and better at a task. Therefore, we need to define what it means to be _good_.\n",
    "\n",
    "For instance, given the output of different models compared to the target variable, which model would you say is better, and why?\n",
    "\n",
    "| Target | 0.55 | 0.72 | 0.6 | 0.54 | 0.42 | 0.65 | 0.44 | 0.89 | 0.96 | 0.38 |\n",
    "|:-------:|:----------:|:----------:|:----------:|:-----:|:-:|:-:|:-:|:-:|\n",
    "| Model A |  0.69 | 2.17 | 1.36 | 0.66 | 0.86 | 0.98 | 1.93 | 0.68 | 1.27 | -0.47 |\n",
    "| Model B  | -1.36 | 1.21 | 1.25 | -0.02 | 2.12 | -0.44 | 0.47 | 0.75 | 2.11 | 1.48 |\n",
    "| Model C |0.59 | 0.81 | 0.38 | 0.04 | 0.33 | 0.69 | 0.75 | 1.19 | 0.86 | 0.3 |\n",
    "| Model D |0.03 | 0.01 | -0.25 | 1.52 | 0.17 | 0.43 | -0.19 | 1.28 | 0.15 | 0.27 |\n",
    "| Model E | 0.1 | 0.91 | 0.34 | -0.05 | 0.41 | 0.86 | 0.47 | 1.04 | 0.64 | 0.2 |\n",
    "\n",
    "This might be difficult to tell, especially if there are more models and predictions. Thankfully, there exists several commonly-used metrics to tackle this problem. Let's use the data from the table as example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "target = np.array([0.55, 0.72, 0.6, 0.54, 0.42, 0.65, 0.44, 0.89, 0.96, 0.38])\n",
    "\n",
    "predictions = {\"A\": np.array([0.69, 2.17, 1.36, 0.66, 0.86, 0.98, 1.93, 0.68, 1.27, -0.47]),\n",
    "               \"B\": np.array([-1.36, 1.21, 1.25, -0.02, 2.12, -0.44, 0.47, 0.75, 2.11, 1.48]),\n",
    "               \"C\": np.array([0.59, 0.81, 0.38, 0.04, 0.33, 0.69, 0.75, 1.19, 0.86, 0.3]),\n",
    "               \"D\": np.array([0.03, 0.01, -0.25, 1.52, 0.17, 0.43, -0.19, 1.28, 0.15, 0.27]),\n",
    "               \"E\": np.array([0.1, 0.91, 0.34, -0.05, 0.41, 0.86, 0.47, 1.04, 0.64, 0.2])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean-Squared Error\n",
    "\n",
    "$ MSE = \\frac{1}{n} \\sum_{i = 0}^{n} (\\hat{Y_i} - Y_i)^2$\n",
    "\n",
    "The mean-squared error is probably the most commonly used metric for regression. It is often set as the default metric in many machine learning packages.\n",
    "\n",
    "It is defined as the average of the square of the errors. It loosely means that large errors are proportionally _worse_ than small mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 0.6099\n",
      "B: 1.1255\n",
      "C: 0.0520\n",
      "D: 0.3785\n",
      "E: 0.0857\n"
     ]
    }
   ],
   "source": [
    "def MSE(predicted_target, target):\n",
    "    errors = predicted_target - target\n",
    "    \n",
    "    return np.mean(errors**2)\n",
    "\n",
    "for model_name, predicted_target in predictions.items():\n",
    "    print(f\"{model_name}: {MSE(predicted_target, target):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean-Squared Error\n",
    "\n",
    "$ RMSE = \\sqrt{\\frac{1}{n} \\sum_{i = 0}^{n} (\\hat{Y_i} - Y_i)^2}$\n",
    "\n",
    "The root mean-squared error is related to the mean squared error. It is simply the square root of the former metric. It has the advantage of being of the same units as the target variable. Therefore, it can be easily interpreted as the average distance of the output to the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 0.7810\n",
      "B: 1.0609\n",
      "C: 0.2281\n",
      "D: 0.6153\n",
      "E: 0.2927\n"
     ]
    }
   ],
   "source": [
    "def RMSE(predicted_target, target):\n",
    "    return np.sqrt(MSE(predicted_target, target))\n",
    "\n",
    "for model_name, predicted_target in predictions.items():\n",
    "    print(f\"{model_name}: {RMSE(predicted_target, target):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error\n",
    "\n",
    "$ MAE = \\frac{1}{n} \\sum_{i = 0}^{n} |\\hat{Y_i} - Y_i|$\n",
    "\n",
    "As opposed to the mean-squared error, the mean absolute error views all errors as proportionally as bad and therefore, large errors are not penalized more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 0.6100\n",
      "B: 0.8820\n",
      "C: 0.1770\n",
      "D: 0.5470\n",
      "E: 0.2390\n"
     ]
    }
   ],
   "source": [
    "def MAE(output, target):\n",
    "    errors = output - target\n",
    "    \n",
    "    return np.mean(np.abs(errors))\n",
    "\n",
    "for model_name, predicted_target in predictions.items():\n",
    "    print(f\"{model_name}: {MAE(predicted_target, target):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R Squared\n",
    "\n",
    "$ R^{2} = 1 - \\frac{\\sum_{i=0}^{n} (Y_i - \\hat{Y_i})^2}{\\sum_{i=0}^{n} (Y_i - \\sum_{i=0}^n Y_i)^2}$\n",
    "\n",
    "R squared is also often referred to as the coefficient of determination, or the explained variance. It represents how much of the target's variance can be explained by the data. 1 is best, lower is worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: -16.8947\n",
      "B: -32.0216\n",
      "C: -0.5265\n",
      "D: -10.1061\n",
      "E: -1.5134\n"
     ]
    }
   ],
   "source": [
    "def RSquared(predicted_target, target):\n",
    "    numerator = np.sum((target - predicted_target)**2)\n",
    "    denominator = np.sum((target - np.mean(target))**2)\n",
    "    \n",
    "    return 1.0 - (numerator / denominator)\n",
    "\n",
    "for model_name, predicted_target in predictions.items():\n",
    "    print(f\"{model_name}: {RSquared(predicted_target, target):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom metrics\n",
    "\n",
    "Of course, it is completely possible to use custom metrics.\n",
    "\n",
    "A simple example would be to use weighted versions of the aforementioned metrics. By doing this, you would loosely make it more important to perform well for certain data points than others. It could also be possible to have a fully custom metric based on a custom error function. Perhaps, your application entails that it is much worse to overshoot rather than undershoot for instance.\n",
    "\n",
    "The metric should ultimately represent what it means for your regression to be good, whatever it may mean in your application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common challenges\n",
    "\n",
    "### Over- or underfitting, the bias-variance dilemma\n",
    "\n",
    "Like in most machine learning problems, regression models might deal with noise in their training data. A big challenge is to figure out how biased we want to be towards our data. If we have a high bias, it means that we are quite sceptical about whether a data point isn't noise. If we have a low bias - and therefore a high variance - it means that we trust most data points to not be noise.\n",
    "\n",
    "\n",
    "![Title](../../../source/visualization/images/regression_bias_variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical examples\n",
    "\n",
    "Below, we mention a few examples of regression problems.\n",
    "\n",
    "+ **Predicting house prices**\n",
    "\n",
    "_Input variables_: Number of bedrooms, whether it has a garage, living surface, age of the house\n",
    "\n",
    "_Target variable_: Price of the house\n",
    "\n",
    "_Example_:\n",
    "\n",
    "| Bedrooms | Garage | Living surface | Age | Price ($) |\n",
    "|:------------:|:------------:|:------------:|:------------:|:---------------:|\n",
    "|3          | 0          | 3000          | 1         | 245000              |\n",
    "| 2          | 1          | 2650          | 14          | 312040              |\n",
    "| 4          | 0          | 4000          | 60          | 180000              |\n",
    "| ...        | ...        | ...        | ...        | ...             |\n",
    "| 5       | 1       | 5432       | 4       | 800670            |\n",
    "\n",
    "This could be useful to make an estimate on a house, either if you're selling or buying one.\n",
    "\n",
    "+ **Predicting student's grades**\n",
    "\n",
    "_Input variables_: Grade on last test, GPA\n",
    "\n",
    "_Target variable_: Grade on final exam\n",
    "\n",
    "_Example_:\n",
    "\n",
    "| Last test | GPA | Final Exam |\n",
    "|:------------:|:------------:|:------------:|\n",
    "|3          | 5.5          | 5          | \n",
    "| 10          | 7          | 6          |\n",
    "| 7          | 8          | 7.5          | \n",
    "|...        | ...        | ...        |\n",
    "| 8       | 9.2       | 10       |\n",
    "\n",
    "A teacher could use this to identify which students might require additional attention.\n",
    "\n",
    "+ **Predict how likely it is for a customer to default on a loan**\n",
    "\n",
    "_Input variables_: Income, age, children, married\n",
    "\n",
    "_Target variable_: Likelihood of defaulting\n",
    "\n",
    "_Example_:\n",
    "\n",
    "| Income | Age | Children | Married | Likelihood of defaulting |\n",
    "|:------------:|:------------:|:------------:|:------------:|:---------------:|\n",
    "|2500          | 33         | 1          | 1         | 0              |\n",
    "| 1200         | 42          | 3          | 1         | 1              |\n",
    "| 0          | 18          | 2          | 0          | 1              |\n",
    "| ...        | ...        | ...        | ...        | ...             |\n",
    "| 9000       | 28       | 0       | 0       | 0            |\n",
    "\n",
    "A bank could use this to decide whether or not to grant a loan."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
